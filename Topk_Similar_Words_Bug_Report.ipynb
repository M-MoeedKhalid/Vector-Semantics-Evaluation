{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topk_Similar_Words.ipynb",
      "provenance": [],
      "mount_file_id": "1SRb-J3SzcSV6baa91pcBKQYNiBwrcoig",
      "authorship_tag": "ABX9TyMhAoZfPSpgLVbLFcheSQ7R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosseinfani/Vector-Semantics-Evaluation/blob/main/Topk_Similar_Words_Bug_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX6gEqUFgLLx"
      },
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "def readfile(filepath, indexes=None):\n",
        "    if not indexes:\n",
        "        indexes = [0, 1, 2]\n",
        "    file1 = open(filepath)\n",
        "    count = 0\n",
        "    dictionary = defaultdict(dict)\n",
        "\n",
        "    while True:\n",
        "        count += 1\n",
        "        line = file1.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        file_tokens = line.strip().split()\n",
        "        dictionary[str(file_tokens[indexes[0]])][str(file_tokens[indexes[1]])] = file_tokens[indexes[2]]\n",
        "\n",
        "    file1.close()\n",
        "    return dictionary\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alvyUDkNg98n"
      },
      "source": [
        "def getmapandndcg(ground_truth_model, w2v):\n",
        "    # keys =\n",
        "    # map = 0\n",
        "    # ndcg = 0\n",
        "    # total = 0\n",
        "    # exists = 0\n",
        "    for key in list(ground_truth_model.keys()):\n",
        "        print(f\"For word {key}:\")\n",
        "        # sims = dict()\n",
        "        try:\n",
        "            # for sim in w2v.most_similar(key, topn=10):\n",
        "            #     sims[sim[0]] = round(sim[1] * 10, 2)\n",
        "\n",
        "            # sims = normalize_dict(sims,1,10)\n",
        "            ground_truth = ground_truth_model[key]\n",
        "            change = True\n",
        "\n",
        "            if ground_truth.__len__() < 10 and ground_truth.__len__() != 0:\n",
        "                while change:\n",
        "                    length = len(list(ground_truth.keys()))\n",
        "                    change = False\n",
        "                    for key in list(ground_truth.keys()):\n",
        "                        newvalues = ground_truth_model[key]\n",
        "                        if list(newvalues.keys()) not in list(ground_truth.keys()):\n",
        "                            change = True\n",
        "                            ground_truth.update(ground_truth_model[key])\n",
        "                    if len(ground_truth.keys()) == length:\n",
        "                        break\n",
        "            sorted_result = dict(sorted(ground_truth.items(), key=lambda x: x[1]))\n",
        "            ground_truth = {k: sorted_result[k] for k in list(sorted_result)[:10]}\n",
        "            for key, value in ground_truth.items():\n",
        "                ground_truth[key] = round(float(value))\n",
        "            \n",
        "            print(ground_truth)\n",
        "\n",
        "            # qrel = {\n",
        "            #     'q1': ground_truth,\n",
        "            # }\n",
        "\n",
        "            # run = {\n",
        "            #     'q1': sims,\n",
        "            # }\n",
        "            # evaluator = pytrec_eval.RelevanceEvaluator(\n",
        "            #     qrel, {'map', 'ndcg'})\n",
        "            # print(f\"ground_truth is {ground_truth}\")\n",
        "            # print(f\"prediction is {sims}\")\n",
        "            # print(json.dumps(evaluator.evaluate(run), indent=1))\n",
        "            # map = map + evaluator.evaluate(run)['q1']['map']\n",
        "            # ndcg = ndcg + evaluator.evaluate(run)['q1']['ndcg']\n",
        "            # exists = exists + 1\n",
        "            # if evaluator.evaluate(run)['q1']['map'] > 0:\n",
        "            #     total = total + 1\n",
        "            #     # if evaluator.evaluate(run).q1.map !=0 or evaluator.evaluate(run).q1.ndcg !=0 :\n",
        "            # #     result = evaluator.evaluate(run)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "            print(repr(e))\n",
        "\n",
        "    # print(f\"Map is {map}\")\n",
        "    # print(f\"NDCG is {ndcg}\")\n",
        "    #return map, ndcg, total, exists"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAKVCynYhVeP",
        "outputId": "c8a5dcf4-0adc-4c77-8db3-93ff59504ff5"
      },
      "source": [
        "# sample.txt\n",
        "# a\tb\t7.35\n",
        "# a\tc\t10.00\n",
        "# b\td\t6\n",
        "# c\te\t6.31\n",
        "# e\tf\t6.77\n",
        "filepath = \"/content/sample.txt\"\n",
        "wordsim_353 = readfile(filepath)\n",
        "getmapandndcg(wordsim_353, None)\n",
        "\n",
        "# For word a:\n",
        "# {'c': 10, 'd': 6, 'e': 6, 'f': 7, 'b': 7}\n",
        "# For word b:\n",
        "# {'d': 6} => should have 'a','c','e', .... because a -> b also b -> a and all similar to a gonna be in b too.\n",
        "# For word c:\n",
        "# {'e': 6, 'f': 7} \n",
        "# For word e:\n",
        "# {'f': 7}"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For word a:\n",
            "{'c': 10, 'e': 6, 'f': 7, 'd': 7, 'b': 7}\n",
            "For word b:\n",
            "{'d': 7}\n",
            "For word c:\n",
            "{'e': 6, 'f': 7}\n",
            "For word e:\n",
            "{'f': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw-ZG2NGjpIT"
      },
      "source": [
        "import networkx as nx\n",
        "def readfile_hossein(filepath, indexes=None, header=False):\n",
        "    g = nx.Graph()\n",
        "    if not indexes:\n",
        "        indexes = [0, 1, 2]\n",
        "    with open(filepath) as file1:\n",
        "        if header: file1.readline()\n",
        "        while True:\n",
        "            line = file1.readline()\n",
        "            if not line: break\n",
        "            file_tokens = line.strip().split()\n",
        "            word1, word2, score = str(file_tokens[indexes[0]]), str(file_tokens[indexes[1]]), float(file_tokens[indexes[2]])\n",
        "            if score > 6:\n",
        "                g.add_edges_from([(word1, word2, {'weight': score})])\n",
        "\n",
        "    top_sim = dict()\n",
        "    for word in g.nodes():\n",
        "        top_sim[word] = {x:1 for x in nx.node_connected_component(g, word) if x != word}\n",
        "\n",
        "    return top_sim"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NALg2oJ2j0by",
        "outputId": "9af82fc7-3ee3-4d1d-fbd5-70ddd897c3d1"
      },
      "source": [
        "filepath = \"/content/sample.txt\"\n",
        "wordsim_353 = readfile_hossein(filepath)\n",
        "print(wordsim_353)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': {'d': 1, 'e': 1, 'b': 1, 'c': 1, 'f': 1}, 'b': {'d': 1, 'e': 1, 'c': 1, 'f': 1, 'a': 1}, 'c': {'d': 1, 'e': 1, 'b': 1, 'f': 1, 'a': 1}, 'd': {'e': 1, 'b': 1, 'c': 1, 'f': 1, 'a': 1}, 'e': {'d': 1, 'b': 1, 'c': 1, 'f': 1, 'a': 1}, 'f': {'d': 1, 'e': 1, 'b': 1, 'c': 1, 'a': 1}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}